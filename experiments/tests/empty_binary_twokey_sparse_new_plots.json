{
    "agent": "dqn",
    "save_weights": true,
    "wandb_mode": "disabled",
    "metaParameters": {
        "total_timesteps": 1000000,
        "seed": 0,
        "n_seeds": 1,
        "env_name": ["EmptyRoom7x7RGBWithTwoKeysSparseReward"],
        "activation": "bernoulli",        
        "network_name": "QNet2",
        "sparsity_coef": [0.0, 1e-6, 1e-4, 1e-3]
    }
}